{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PENGUINS CLASSIFIER documentation!","text":"<p>Welcome to the documentation for PENGUINS CLASSIFIER! This repository uses data from the open Penguin data set available here. A script to download the data is available at scripts/download_data.py. This script requires setting up the Kaggle API.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Prerequisites</li> <li>Installation</li> <li>Usage</li> <li>Deployed model</li> <li>License</li> </ul>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure that the following software is installed on your system:</p> <ul> <li>Python 3.10</li> <li>pip</li> <li>Git</li> </ul> <p>You will also need to clone the repository to your local environment by executing the following commands:</p> <pre><code>git clone https://github.com/lauracabayol/LCG-TestDataScience-1\ncd LCG-TestDataScience-1\n</code></pre>"},{"location":"#installation","title":"Installation","text":""},{"location":"#installation-and-environment-setup","title":"Installation and Environment Setup","text":"<p>We recommend using a virtual environment to install the project dependencies and maintain an isolated workspace.</p>"},{"location":"#setting-up-a-virtual-environment","title":"Setting Up a Virtual Environment:","text":"<p>To create a virtual environment using , run the following commands: <pre><code>python -m venv venv\nsource venv/bin/activate  \n</code></pre>"},{"location":"#2-setting-up-a-conda-environment","title":"2. Setting Up a Conda Environment:","text":"<p>Alternatively, you can create a Conda environment with Python 3.10 by executing the following commands:</p> <pre><code>conda create -n TempForecast -c conda-forge python=3.10\nconda activate TempForecast\n</code></pre> <p>The required python modules are in the  file although these will automatically install when installing the repository. <p>Once your environment is ready, proceed with the installation of the package:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"#optional-configuring-mlflow","title":"Optional: Configuring MLflow","text":"<p>For advanced users interested in tracking experiments and using MLflow, please follow the official MLflow setup guide to configure the tracking server.</p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#running-the-models","title":"Running the Models","text":"<p>This project supports four algorithms:</p> <ul> <li>Gradient Boosting</li> <li>Random Forest</li> <li>Logistic Regression</li> <li>Support Vector Machine (SVM) You can choose any of these algorithms for training and predictions.</li> </ul>"},{"location":"#training-the-model","title":"Training the Model","text":"<p>To train a model, use the following command, specifying the desired algorithm:</p> <pre><code>python VitalMetrics/modeling/train.py --model-type &lt;algorithm name&gt;\n</code></pre> <p>Replace  with one of the following options: - gradient_boosting - random_forest - logistic_regression - svm"},{"location":"#making-predictions","title":"Making Predictions","text":"<p>Once the model is trained, you can use the trained model to make predictions. Run the following command:</p> <pre><code>python VitalMetrics/modeling/predict.py &lt;test features file&gt;\n</code></pre>"},{"location":"#accessing-the-notebooks","title":"Accessing the notebooks","text":"<p>The notebooks are loaded on GitHub as .py files. To convert them to .ipynb use  <pre><code>jupytext --to ipynb notebooks/*.py\n</code></pre>"},{"location":"#accessing-models","title":"Accessing Models","text":"<p>There are three ways of accessing the models.</p>"},{"location":"#accessing-models-from-mlflow","title":"Accessing models from MLFlow","text":"<p>The  access the model registery in MLFlow to make predictions, compare them, and run the necessary plots and metrics. This option is only available for those having the MLFlow logs, which are not uploaded to GitHub.</p> <pre><code>import mlflow.pytorch\n\n# Define the model name and version\nmodel_name = \"PENGUINS CLASSIFIER\"\nmodel_version = 16 #select the version\nmodel_uri = f\"models:/{model_name}/{model_version}\"\n\n# Load the model from MLflow\ndeployed_model = mlflow.sklearn.load_model(model_uri)\n</code></pre>"},{"location":"#deployed-gradient-boosting-model","title":"Deployed Gradient Boosting model","text":"<p>The available deployed model as of today is the Gradient Boosting. There are two different ways of accessing the deployed model:</p>"},{"location":"#through-weights-and-biases","title":"Through weights and biases:","text":"<p>We have deployed the model in the WaB platform and it is available here. This allows the user to make single predictions from a set of features. It is publicly available for everyone and userfriendly, but does not support making predictions for more than one sample simultaneously. </p>"},{"location":"#model-in-a-docker-container","title":"Model in a Docker container:","text":"<p>For convenience, we have created a Docker container that includes the Gradient Boosting model along with all necessary dependencies. This allows you to run the model without needing access to MLflow or the associated logs.</p>"},{"location":"#instructions-to-run-the-docker-container","title":"Instructions to Run the Docker Container:","text":"<p>Build the Docker Image: First, clone the repository and navigate to the project directory. Then, build the Docker image:</p> <pre><code>docker build -t penguin-classificaton:latest .\n</code></pre> <p>Run the Docker Container: Once the image is built, run the container using the following command:</p> <pre><code>docker run -p 9999:9999 penguin-classificaton:latest\n</code></pre> <p>This will start a Jupyter notebook where you can interact with the pre-trained best-performing model.</p> <p>Access the Jupyter Notebook: Open your web browser and go to:</p> <pre><code>http://localhost:9999\n</code></pre> <p>The access token is 12345 The notebook is pre-configured to load and run the best model, so you can use it without needing to access MLflow.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. You are free to use, modify, and distribute this project as long as you adhere to the license terms.</p>"}]}